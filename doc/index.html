<h1>Documentation</h1>

<p>SOL is an large scale sparse online learning library, which consists of a family of
efficient and scalable state-of-art online learning algorithms for large-scale sparse
online classification tasks. The library provide an easy-to-use command-line tool and
several scripts for users and developers.  We performed comprehensive experiments to
verify the efficiency and effectiveness of the library.</p>

<h2>Outline</h2>

<ol>
<li><p><a href="#struct">Structure of folders</a></p></li>
<li><p><a href="#cmd_line">Command line</a></p></li>
<li><p><a href="#tutorial">Tutorial</a></p>

<p> 3.1. <a href="#install">Installation</a></p>

<p> 3.2. <a href="#step_example">A step by step example</a></p></li>
<li><p><a href="#manual">User Manual &amp; Extend the library</a></p>

<p> 4.1. <a href="#io_handler">IO Handlers</a></p>

<p> <ul style="list-style-type:none;">
     <li><p><a href="#parse">4.1.1. Parsing Dataset</a></p></li>
     <li><p><a href="#extend_datareader">4.1.2. Extend the data readers</a></p></li>
 </ul></p>

<p> 4.2. <a href="#loss">Loss Functions</a></p>

<p> 4.3. <a href="#optimizer">Optimizers</a></p>

<p>  <ul style="list-style-type:none;">
     <li><p><a href="#opt_detail">4.3.1. Details of Optimizer</a></p></li>
     <li><p><a href="#opt_own">4.3.2. Implement your own algorithms</a></p></li>
 </ul></p>

<p> 4.4. <a href="#common_util">Common Utilities</a></p></li>
</ol>


<!--
5. [Experimental Results of SOL](#exp)

    5.1. [Experiment on RCV1](#exp_rcv1)

    5.2. [Experiment on kdda](#exp_kdda)
-->


<h2><a id='struct'>1. Structure of folders</a></h2>

<ul>
<li><p>&mdash;doc</p>

<p>documentation of the library</p></li>
<li><p>&mdash;exp</p>

<p>some scripts for experiments</p></li>
<li><p>&mdash;src</p>

<ul>
<li><p>&mdash;common</p>

<p>source code of common utilities and global definitions</p></li>
<li><p>&mdash;data</p>

<p>source code of IO handlers</p></li>
<li><p>&mdash;loss</p>

<p>source code of loss functions</p></li>
<li><p>&mdash;optimizer</p>

<p>source code of large scale sparse online learning algorithms</p></li>
</ul>
</li>
<li><p>&mdash;tools</p>

<p>Some tools to standardize datasets</p></li>
</ul>


<h2><a id='cmd_line'>2. Command line</a></h2>

<p>Running SOL without any arguments or with &lsquo;&ndash;help&rsquo; will produce a message which briefly explains each argument. Below
arguments are grouped according to their function.</p>

<h4>Input Options</h4>

<pre><code>-i  arg :    file path to the training data
-c  arg :    file path to the cached training data
-t  arg :    file path to the test data
-tc arg :    file path to the cached test data
-dt arg :    data type option, only LibSVM is supported by default
-bs arg :    number of chunks for buffering, default is 2
</code></pre>

<h3>Loss Functions</h3>

<pre><code>-loss arg:      loss function type

supported loss functions:
*   Hinge:          hinge loss 
*   Logit:          logistic loss
*   Square:         square loss
*   SquareHinge:    squared hinge loss
</code></pre>

<h3>Algorithms and parameters</h3>

<pre><code>-opt arg :      optimization algorithms, options include:
                SGD, STG, RDA, RDA_E, FOBOS, Ada-RDA, Ada-FOBOS, AROW
-eta arg :      learning rate, if this option is not specified, algorithms will 
                try difference parameters and select a best one automatically         
-l1  arg :      L1 regularization parameter
-passes arg:    number of passes to go through 
</code></pre>

<h4>Algorithm list</h4>

<ul>
<li><p><strong>SGD</strong></p>

<p>Stochastic Gradient Descent algorithm. Note that no sparsity is induced even a L1 regularization parameter is set.</p></li>
<li><p><strong>STG</strong></p>

<p>Truncated Gradient Descent algorithm.</p>

<p><em>Parameter</em>:</p>

<pre><code>-k  arg :       truncate the weight vector every k steps
</code></pre>

<p><em>Reference</em>:</p>

<pre><code>Langford J, Li L, Zhang T. Sparse online learning via truncated gradient[J]. The Journal of Machine Learning Research, 2009, 10: 777-801. 
</code></pre></li>
<li><p><strong>RDA</strong></p>

<p>Regularized Dual Averaging algorithm. L1 regularization is implemented.</p>

<p><em>Reference</em>:</p>

<pre><code>Xiao L. Dual averaging methods for regularized stochastic learning and online optimization[J]. The Journal of Machine Learning Research, 2010, 9999: 2543-2596.  
</code></pre></li>
<li><p><strong>RDA_E</strong></p>

<p>Enhanced L1-Regularized Dual Averaging algorithm.</p>

<p><em>Parameter</em>:</p>

<pre><code>-gammarou arg :      decreased L1 regularization parameter.
</code></pre>

<p><em>Reference</em>:</p>

<pre><code>Xiao L. Dual averaging methods for regularized stochastic learning and online optimization[J]. The Journal of Machine Learning Research, 2010, 9999: 2543-2596.  
</code></pre></li>
<li><p><strong>FOBOS</strong></p>

<p>Forward Backward Splitting algorithm.</p>

<p><em>Reference</em>:</p>

<pre><code>Duchi J, Singer Y. Efficient online and batch learning using forward backward splitting[J]. The Journal of Machine Learning Research, 2009, 10: 2899-2934.  
</code></pre></li>
<li><p><strong>Ada-RDA</strong></p>

<p>Adaptive Regularized Dual Averaging algorithm.</p>

<p><em>Parameter</em>:</p>

<pre><code>-delta arg :    parameter to ensure positive-definite property of the adaptive weighting matrix
</code></pre>

<p><em>Reference</em>:</p>

<pre><code>Duchi J, Hazan E, Singer Y. Adaptive subgradient methods for online learning and stochastic optimization[J]. The Journal of Machine Learning Research, 2011, 999999: 2121-2159.
</code></pre></li>
<li><p><strong>Ada-FOBOS</strong></p>

<p>Adaptive Forward Backward Splitting algorithm.</p>

<p><em>Parameter</em>:</p>

<pre><code>-delta arg :    parameter to ensure positive-definite property of the adaptive weighting matrix
</code></pre>

<p><em>Reference</em>:</p>

<pre><code>Duchi J, Hazan E, Singer Y. Adaptive subgradient methods for online learning and stochastic optimization[J]. The Journal of Machine Learning Research, 2011, 999999: 2121-2159.
</code></pre></li>
<li><p><strong>AROW</strong></p>

<p>Adaptive Regularization of weighted vectors.</p>

<p><em>Parameter</em>:</p>

<pre><code>-r arg :    parameter of passive-aggressive update trade-off
</code></pre>

<p><em>Reference</em>:</p>

<pre><code>rammer K, Kulesza A, Dredze M. Adaptive regularization of weight vectors[J]. Machine Learning, 2009: 1-33.
</code></pre></li>
<li><p><strong>ASAROW</strong></p>

<p>Adaptive Regularization of weighted vectors for feature selection.</p>

<p><em>Parameter</em>:</p>

<pre><code>-k arg :    number of weight dimenstions to keep
</code></pre></li>
<li><p><strong>SSAROW</strong></p>

<p>Truncated Sparse Adaptive Regularization of weighted vectors.</p>

<p><em>Parameter</em>:</p>

<pre><code>-r arg :    parameter of passive-aggressive update trade-off
</code></pre></li>
<li><p><strong>CW-RDA</strong></p>

<p>Confidence weighted dual avearaging regularization</p>

<p><em>Parameter</em>:</p>

<pre><code>-r arg :    parameter of passive-aggressive update trade-off
</code></pre></li>
<li><p><strong>SCW</strong></p>

<p>Exact Soft-Confidence Weighted Learning (To be verified)</p>

<p><em>Parameter</em>:</p>

<pre><code>-phi arg:   probability parameter in SCW

-r arg  :    parameter of passive-aggressive update trade-off
</code></pre></li>
<li><p><strong>SCW-RDA</strong></p>

<p>Exact Soft-Confidence Weighted Learning with regularized dual averaing (To be verified)</p>

<p><em>Parameter</em>:</p>

<pre><code>-phi arg:   probability parameter in SCW

-r arg  :    parameter of passive-aggressive update trade-off
</code></pre></li>
</ul>


<h2><a id='tutorial'>3. Tutorial</a></h2>

<h3><a id='install'>3.1 Installation</a></h3>

<p>SOL features a very simple installation procedure. The project is managed by Cmake. There exists a <code>CMakeLists.txt</code> in the root dir of SOL.</p>

<ol>
<li><p>For linux users</p>

<ol>
<li><p><code>cd</code> to the directory of SOL</p></li>
<li><p>make a folder for building the project, like  <code>mkdir build</code></p></li>
<li><p><code>cd</code> to the folder above and call cmake</p></li>
<li><p><code>make</code> and you will get an executable <code>SOL</code> in the <code>bin</code> folder</p></li>
<li><p><code>make install</code> and the executable will be copied to the root dir of SOL</p></li>
</ol>
</li>
<li><p>For windows users</p>

<ol>
<li><p>make a folder for building the project</p></li>
<li><p>call cmake. Remember to specify the visual studio. For example, if you are using Visual Studio 2012, you can
generate the project by</p>

<pre><code> cmake -G "Visual Studio 11" ..
</code></pre></li>
<li><p>Open the project, Rebuild the <code>ALL_BUILD</code> project and then build the <code>INSTALL</code> project</p></li>
</ol>
</li>
</ol>


<p>In the <code>vs</code> directory, we provide a Visual Studio 2012 Project.</p>

<h3>3.2 <a id='step_example'>A step-by-step example</a></h3>

<p>In this section, we provide an example to show how to use SOL and explain the details of how SOL works.
The dataset we use will be <code>a6a</code>. Note that only LibSVM datasets are supported by default.</p>

<h4>3.2.1 SGD</h4>

<p>The command for training is the following.</p>

<pre><code>./SOL -i a6a -opt SGD
</code></pre>

<p>The output will be:</p>

<pre><code>eta0 = 1e-08    mistake rate: 24.0107 %
eta0 = 1e-07    mistake rate: 24.0107 %
eta0 = 1e-06    mistake rate: 24.0107 %
eta0 = 1e-05    mistake rate: 24.0107 %
eta0 = 0.0001   mistake rate: 24.0107 %
eta0 = 0.001    mistake rate: 20.8913 %
eta0 = 0.01 mistake rate: 17.041 %
eta0 = 0.1  mistake rate: 17.3797 %
eta0 = 1    mistake rate: 20.6506 %
Best Parameter: eta = 0.01

--------------------------------------------------
Algorithm: STG
Learn error rate: 17.04 +/- 0.00 %
Sparsification Rate: 0.00 %
Learning time: 0.110 s
</code></pre>

<p>First, SOL will try different learning rates and then select the best one. If you do know the best learning rate,
you can specify by:</p>

<pre><code>./SOL -i a6a -opt SGD -eta 0.01
</code></pre>

<h4>3.2.2 STG</h4>

<p>In this part, we will explain how to induce sparsity of the weight vector and how to tune parameters of algorithms.
In STG, we can induce sparsity by:</p>

<pre><code>./SOL -i a6a -opt STG -eta 0.01 -l1 1e-3
</code></pre>

<p>The output will be:</p>

<pre><code>--------------------------------------------------
Algorithm: STG
Learn error rate: 17.17 +/- 0.00 %
Sparsification Rate: 36.07 %
Learning time: 0.027 s
</code></pre>

<p>We can see that the sparsification rate is much larger than that of SGD.</p>

<p>Also,we can change the number of steps to truncate the gradients (default is 10).</p>

<pre><code>./SOL -i a6a -opt STG -eta 0.01 -l1 1e-3 -k 1
</code></pre>

<p>The output is almost the same to the default in this example.</p>

<h2>4. <a id='manual'>User Manual &amp; Extend the library</a></h2>

<p>In this section, we will explain the details of the source code. The library is constituted of four major parts:
<em>IO Handler</em>, <em>Loss Functions</em>, <em>Optimizers</em>, and <em>Common Utilities</em>.</p>

<h3>4.1 <a id='io_handler'>IO Handler</a></h3>

<p>IO Handler is in charge of data loading. The three major functions are: parsing the original dataset, caching data, and
a common interface with optimizers.</p>

<h4>4.1.1 <a id='parse'>Parsing dataset</a></h4>

<p>It requires different codes to parse different formats of data. By default, we only support LibSVM format. The base
class to parse a dataset is <code>DataReader</code> (in <em>DataReader.h</em>), in which we define the interfaces to load a dataset file
correctly. The interfaces are:</p>

<ul>
<li><p>OpenReading</p>

<pre><code>virtual bool OpenReading() = 0;
</code></pre>

<p>Open a dataset file to load data. Note that we do not specify the source of dataset (like a file path name), as the
source of data may be online sources (like TCP). The <code>open</code> operation can go beyond opening a local file. It can
also open a socket listener.</p>

<p>Return true if everything is ok.</p></li>
<li><p>GetNextData</p>

<pre><code>virtual bool GetNextData(DataPoint&lt;FeatType, LabelType&gt; &amp;data) = 0;
</code></pre>

<p>Get a new data point from the source. <code>data</code> is the variable to place the obtained data.</p>

<p>Return true if everything is ok.</p></li>
<li><p>Rewind</p>

<pre><code>virtual void Rewind() = 0;
</code></pre>

<p>Rewind the data source to the beginning</p></li>
<li><p>Close</p>

<pre><code>virtual void Close() = 0;
</code></pre>

<p>Close the data source when loading is finished.</p></li>
<li><p>Good</p>

<pre><code>virtual bool Good() = 0;
</code></pre>

<p>Test if the data reader is ok.</p></li>
</ul>


<h4>4.1.2 <a id='extend_datareader'>Extend the data readers</a></h4>

<p>For a specific format of data, we only need to inherit from the  <code>DataReader</code> class and implement the above interfaces.
It will work when you assign the customized data reader to the dataset.</p>

<p>The file <code>libsvmread.h</code> can be regarded as an example to extend the <code>DataReader</code>.</p>

<h3>4.2 <a id='loss'>Loss Functions</a></h3>

<p>At the moment, we provide a base class (purely virtual class) for loss functions and two child classes(HingleLoss and
Logistic Loss). The interfaces are:</p>

<ul>
<li><p>IsCorrect</p>

<pre><code>virtual inline bool IsCorrect(LabelType label, float predict);
</code></pre>

<p>This function is implemented in the base class to justify whether a prediction is correct for binary classification
problems. We assign the virtual property to it for the extensibility to multi-class or regression problems.</p></li>
<li><p>GetLoss</p>

<pre><code>virtual float GetLoss(LabelType label, float predict) = 0;
</code></pre>

<p>Get the loss of the current prediction</p></li>
<li><p>GetGradient</p>

<pre><code>virtual float GetGradient(LabelType label, float predict) = 0;
</code></pre>

<p>Get the gradient of the loss function at the current data point. Note that we do not calculate the exact gradient
here. To linear classification problems, the gradients on different features share a same part. Take Hinge Loss for
example:</p>

<p><i>l(<b>w</b>) = 1 - y <b>w</b> &#8226; <b>x</b></i></p>

<p>The gradient is:</p>

<p><i>l&#39;(<b>w</b>) = -y <b>x</b></i></p>

<p>As a result, we only calculate the shared term <code>-y</code> for the gradients of different features for efficiency concern.
Users need to multiply the correspondent feature <code>x[i]</code> in the optimization algorithms.</p></li>
</ul>


<h4>4.2.1 Extend loss functions</h4>

<p>The files &lsquo;HingeLoss.h&rsquo;, &lsquo;LogisticLoss.h&rsquo;, &lsquo;SquareLoss.h&rsquo;, and
&lsquo;SquareHingeLoss.h&rsquo;  are three examples to extend the base class.</p>

<h3>4.3 <a id='optimizer'>Optimizers</a></h3>

<p>Optimizers are the online learning algorithms.  The base class <code>Optimizer</code> implements the details of how a linear
classification model works, including interacting with a dataset, training the model, updating the model, test the
model, and some other auxiliary functions. It also define the interfaces for different learning algorithms(those virtual
functions).</p>

<h4>4.3.1 <a id='opt_detail'>Details of Optimizer class</a></h4>

<h5>Class Members</h5>

<ul>
<li><code>curIterNum</code>:   current iteration number</li>
<li><code>initial_t</code>:    initial iteration number, this is the variable to avoid large learning rates at the beginning</li>
<li><code>eta0</code>:         initial learning rate</li>
<li><code>eta</code> :         learning rates. This variable is set to <code>eta0</code> at the when training begins. Different algorithms can
                set the value of learning rate on the fly.</li>
<li><code>lambda</code>:       The L1 regularization parameter.</li>
<li><code>dataSet</code>:      The training and test data source.</li>
<li><code>weightVec</code>:    The weight vector of the linear model.</li>
<li><code>weightDim</code>:    current dimension of the weight vector. Note that this variable is changing with training data
                coming in.</li>
<li><code>sparse_soft_thresh</code>:
                threshold below which a weight is regarded as zero.</li>
<li><code>lossFunc</code> :    user specified loss function</li>
<li><code>id_str</code> :      a string to describe the algorithm, need to be assigned a value when an algorithm is constructed</li>
</ul>


<h5>Class Methods</h5>

<p><strong>Constructor</strong></p>

<pre><code>    Optimizer(DataSet&lt;FeatType, LabelType&gt; &amp;dataSet, LossFunc&lt;FeatType, LabelType&gt; &amp;lossFunc); 
</code></pre>

<p>When initializing an optimizer, users need to assign the data set and the loss function at least.</p>

<p><strong>Destructor</strong></p>

<pre><code>    virtual ~Optimizer();
</code></pre>

<p>Destroy the optimizer and release memory.</p>

<p><strong>Learning</strong></p>

<ol>
<li><p>Learn</p>

<pre><code>float Learn(int numOfTimes = 1);
</code></pre>

<p>Learn a model and return the average error rate. Note that the input parameter is only used for those dataset that
can be randomized. It is not available at the moment.</p>

<pre><code>float Learn(float &amp;aveErrRate, float &amp;varErrRate, float&amp; sparseRate, int numOfTimes = 1);
</code></pre>

<p>Learn a model and return the average error rate.</p>

<p><strong>Parameters</strong></p>

<ul>
<li><code>aveErrRate</code>:   average error rate</li>
<li><code>varErrRate</code>:   variance of the average error rate, only valid when dataset can be randomized</li>
<li><code>sparesRate</code>:   sparsification rate of the linear model</li>
<li><code>numOfTimes</code>:   number of times to learn the model with randomized dataset, not available at the moment</li>
</ul>
</li>
<li><p>BeginTrain</p>

<pre><code>virtual void BeginTrain();
</code></pre>

<p>Reset the optimizer to the initialization status  of training</p>

<p><strong>Note:</strong>   Users should call this base function explicitly in their inherited function to ensure the model is reset correctly.</p></li>
<li><p>Train</p>

<pre><code>float Train();
</code></pre>

<p>Train the model and return the learning error rate.</p></li>
<li><p>EndTrain</p>

<pre><code>virtual void EndTrain();
</code></pre>

<p>Called when training is finished.</p></li>
<li><p>Predict</p>

<pre><code>float Predict(DataPoint&lt;FeatType, LabelType&gt; &amp;data);
</code></pre>

<p>Predict the label of the input data point.</p></li>
<li><p>UpdateWeightVec</p>

<pre><code>virtual float UpdateWeightVec(const DataPoint&lt;FeatType, LabelType&gt; &amp;x) = 0;
</code></pre>

<p>The core function of learning. This function is called each time a new data point comes to update the model.</p>

<p><code>x</code>: the new data that comes in</p>

<p><strong>Return</strong>: the prediction of the input data <code>x</code></p></li>
</ol>


<p><strong>Test</strong></p>

<pre><code>    float Test(DataSet&lt;FeatType ,LabelType&gt; &amp;testSet);
</code></pre>

<p>Test the performance of the given dataset. Return the test error rate.</p>

<p><strong>Auxiliary Function</strong></p>

<ol>
<li><p>SetParameter</p>

<pre><code>void SetParameter(float lambda = -1, float eta0 = -1);
</code></pre>

<p>Set the learning rate and L1 regularization parameter. <code>-1</code> means no change.</p></li>
<li><p>BestParameter()</p>

<pre><code>virtual void BestParameter();
</code></pre>

<p>Learn the best learning rate by default. It can be inherited and learn other parameters to satisfy the requirements
of different algorithms.</p></li>
<li><p>GetSparseRate</p>

<pre><code>float GetSparseRate(int total_len = 0);
</code></pre>

<p>Get the sparse rate of the model. The total_len is the dimension of the input data. If not assigned by users, the
largest index of features will be used.</p></li>
<li><p>UpdateWeightSize</p>

<pre><code>virtual void UpdateWeigthSize(int newDim);
</code></pre>

<p>Update the dimension of the weight vector. As we are learning on sparse data online, we do not know the dimension of
the input data. So the weight vector needs to be resized on the fly.
Note that inherited algorithms need to override this function to resize their own dimension-related members and call
the base one explicitly to resize the weight vector.</p></li>
<li><p>PrintOptInfo</p>

<pre><code>void PrintOptInfo() const;
</code></pre>

<p>Print the optimization information.</p></li>
<li><p>Id_Str</p>

<pre><code>const string&amp; Id_Str() const;
</code></pre>

<p>Get the identity string of the optimizer.</p></li>
</ol>


<h4>4.3.2 <a id='opt_own'>Implement your own algorithms</a></h4>

<p>To implement a specific learning algorithm, you only need to inherit from the base class <code>Optimizer</code>, and implement
the pure virtual function <code>UpdateWeightVec</code>. Whether other virtual functions need to be override depends on the
specific algorithm. Take STG for example, it has to maintain a time stamp vector. So it override the <code>BeginTrain</code>
and <code>UpdateWeightSize</code> functions to initialize and resize the time stamp vector. It needs to shrink weight vectors
at the end of the training. So <code>EndTrain</code> is override.</p>

<p>Check the implemented algorithms to explore more details of how to extend the optimizers.</p>

<h3>4.4 <a id='common_util'>Common Utilities</a></h3>

<p>For some utilized functions and global definitions, please refer to
<em>&lsquo;common/init_param.h&rsquo;</em> and <em>&lsquo;common/util.h&rsquo;</em>.</p>

<p><br/>
<br/></p>

<!--
## <a id='exp'>Experimental Results of SOL</a>

### <a id='exp_rcv1'>Experiment on RCV1 </a>

### <a id='exp_kdda'>Experiment on kdda</a>
-->

